row.index<- nrow(train)+1:nrow(dat)
row.index
# figure out the block you need
row.index<- nrow(train)+1:nrow(test)
row.index
col.index<- 1:nrow(train)
col.index
submat<- dist.mat[row.index, col.index]
submat
# figure out the block you need
row.index<- c(nrow(train)+1:nrow(test))
col.index<- c(1:nrow(train))
submat<- dist.mat[row.index, col.index]
y
test
myknn<- function(train, test, cl, k){
# define a 0 vector to save your predictions for testing sample
pred<- rep(0, nrow(test))
# obtain the full distance matrix (excluding the column y)
dist.mat<- as.matrix(dist(rbind(train, test)))
# figure out the block you need
row.index<- nrow(train)+1:nrow(test)
col.index<- 1:nrow(train)
submat<- dist.mat[row.index, col.index]
# for loop to find prediction for each testing point
for(i in 1:nrow(test)){
# find the index of k nearest points in training sample
# you may use function `order()` to find the index of nearest point
neighbor.index<- order(submat[i,])
# find y's of those k nearest points
neighbor.y<- neighbor.index[1:k]
# take majority vote as the prediction
pred[i]<- ifelse(mean(neighbor.y)>0.5, 1,0)
}
return(pred)
}
# test your function and compare with knn()
myknn.pred<- myknn(train=train[,-1], test=test[,-1], cl=train$y, k=5)
knn.pred<- knn(train=train[,-1], test=test[,-1], cl=train$y, k=5)
sum(myknn.pred!=knn.pred)
myknn.pred
train
myknn<- function(train, test, cl, k){
# define a 0 vector to save your predictions for testing sample
pred<- rep(0, nrow(test))
# obtain the full distance matrix (excluding the column y)
dist.mat<- as.matrix(dist(rbind(train, test)))
# figure out the block you need
row.index<- nrow(train)+1:nrow(test)
col.index<- 1:nrow(train)
submat<- dist.mat[row.index, col.index]
# for loop to find prediction for each testing point
for(i in 1:nrow(test)){
# find the index of k nearest points in training sample
# you may use function `order()` to find the index of nearest point
neighbor.index<- order(submat[i,])
# find y's of those k nearest points
neighbor.y<- neighbor.index[1:k]
# take majority vote as the prediction
pred[i]<- ifelse(sum(neighbor.y)>k/2, 1,0)
}
return(pred)
}
# test your function and compare with knn()
myknn.pred<- myknn(train=train[,-1], test=test[,-1], cl=train$y, k=5)
knn.pred<- knn(train=train[,-1], test=test[,-1], cl=train$y, k=5)
sum(myknn.pred!=knn.pred)
# find the index of k nearest points in training sample
# you may use function `order()` to find the index of nearest point
neighbor.index<- order(submat[1,])
neighbor.index
submat[1,]
submat[1,]
# find the index of k nearest points in training sample
# you may use function `order()` to find the index of nearest point
neighbor.index<- order(submat[1,])
neighbor.index
order(submat[1,])
submat[1,]
submat[1,][194]
neighbor.y
# find y's of those k nearest points
neighbor.y<- neighbor.index[1:5]
neighbor.y
neighbor.y[1,]
grep(neighbor.y,submat)
neighbor.y
# take majority vote as the prediction
pred[1]<- train[194,]
train[194,]
# take majority vote as the prediction
pred[1]<- train[194,1]
train[194,1]
pred[1]<- sapply(sapply(train[,1], function(x) grep(neighbor.y), function(x) ifelse(,1,0))
pred[1]
# take majority vote as the prediction
pred[1]<- sapply(sapply(train[,1], function(x) grep(neighbor.y), function(x) ifelse(,1,0))
}
cl=train$y
mean(cl[neighbor.y])
cl[neighbor.y]
myknn<- function(train, test, cl, k){
# define a 0 vector to save your predictions for testing sample
pred<- rep(0, nrow(test))
# obtain the full distance matrix (excluding the column y)
dist.mat<- as.matrix(dist(rbind(train, test)))
# figure out the block you need
row.index<- nrow(train)+1:nrow(test)
col.index<- 1:nrow(train)
submat<- dist.mat[row.index, col.index]
# for loop to find prediction for each testing point
for(i in 1:nrow(test)){
# find the index of k nearest points in training sample
# you may use function `order()` to find the index of nearest point
neighbor.index<- order(submat[i,])
# find y's of those k nearest points
neighbor.y<- neighbor.index[1:k]
# take majority vote as the prediction
pred[i]<- ifelse(mean(cl[neighbor.y])>0.5,1,0)
}
return(pred)
}
# test your function and compare with knn()
myknn.pred<- myknn(train=train[,-1], test=test[,-1], cl=train$y, k=5)
knn.pred<- knn(train=train[,-1], test=test[,-1], cl=train$y, k=5)
sum(myknn.pred!=knn.pred)
myknn.pred
knn.pred
# test your function and compare with knn()
myknn.pred<- myknn(train=train[,-1], test=test[,-1], cl=train$y, k=5)
knn.pred<- knn(train=train[,-1], test=test[,-1], cl=train$y, k=5)
sum(myknn.pred!=knn.pred)
myknn<- function(train, test, cl, k){
# define a 0 vector to save your predictions for testing sample
pred<- rep(0, nrow(test))
# obtain the full distance matrix (excluding the column y)
dist.mat<- as.matrix(dist(rbind(train, test)))
# figure out the block you need
row.index<- nrow(train)+1:nrow(test)
col.index<- 1:nrow(train)
submat<- dist.mat[row.index, col.index]
# for loop to find prediction for each testing point
for(i in 1:nrow(test)){
# find the index of k nearest points in training sample
# you may use function `order()` to find the index of nearest point
neighbor.index<- order(submat[i,])
# find y's of those k nearest points
neighbor.y<- neighbor.index[1:k]
# take majority vote as the prediction
pred[i]<- majority(cl[neighbor.y])
}
return(pred)
}
# test your function and compare with knn()
myknn.pred<- myknn(train=train[,-1], test=test[,-1], cl=train$y, k=5)
myknn<- function(train, test, cl, k){
# define a 0 vector to save your predictions for testing sample
pred<- rep(0, nrow(test))
# obtain the full distance matrix (excluding the column y)
dist.mat<- as.matrix(dist(rbind(train, test)))
# figure out the block you need
row.index<- nrow(train)+1:nrow(test)
col.index<- 1:nrow(train)
submat<- dist.mat[row.index, col.index]
# for loop to find prediction for each testing point
for(i in 1:nrow(test)){
# find the index of k nearest points in training sample
# you may use function `order()` to find the index of nearest point
neighbor.index<- order(submat[i,])
# find y's of those k nearest points
neighbor.y<- neighbor.index[1:k]
# take majority vote as the prediction
pred[i]<- which.max(cl[neighbor.y])
}
return(pred)
}
# test your function and compare with knn()
myknn.pred<- myknn(train=train[,-1], test=test[,-1], cl=train$y, k=5)
knn.pred<- knn(train=train[,-1], test=test[,-1], cl=train$y, k=5)
sum(myknn.pred!=knn.pred)
myknn<- function(train, test, cl, k){
# define a 0 vector to save your predictions for testing sample
pred<- rep(0, nrow(test))
# obtain the full distance matrix (excluding the column y)
dist.mat<- as.matrix(dist(rbind(train, test)))
# figure out the block you need
row.index<- nrow(train)+1:nrow(test)
col.index<- 1:nrow(train)
submat<- dist.mat[row.index, col.index]
# for loop to find prediction for each testing point
for(i in 1:nrow(test)){
# find the index of k nearest points in training sample
# you may use function `order()` to find the index of nearest point
neighbor.index<- order(submat[i,])
# find y's of those k nearest points
neighbor.y<- neighbor.index[1:k]
# take majority vote as the prediction
pred[i]<- ifelse(mean(cl[neighbor.y])>0.5,1,0)
}
return(pred)
}
# test your function and compare with knn()
myknn.pred<- myknn(train=train[,-1], test=test[,-1], cl=train$y, k=5)
knn.pred<- knn(train=train[,-1], test=test[,-1], cl=train$y, k=5)
sum(myknn.pred!=knn.pred)
myknn<- function(train, test, cl, k){
# define a 0 vector to save your predictions for testing sample
pred<- rep(0, nrow(test))
# obtain the full distance matrix (excluding the column y)
dist.mat<- as.matrix(dist(rbind(train, test)))
# figure out the block you need
row.index<- nrow(train)+1:nrow(test)
col.index<- 1:nrow(train)
submat<- dist.mat[row.index, col.index]
# for loop to find prediction for each testing point
for(i in 1:nrow(test)){
# find the index of k nearest points in training sample
# you may use function `order()` to find the index of nearest point
neighbor.index<- order(submat[i,])
# find y's of those k nearest points
neighbor.y<- neighbor.index[1:k]
# take majority vote as the prediction
pred[i]<- mode(cl[neighbor.y])
}
return(pred)
}
# test your function and compare with knn()
myknn.pred<- myknn(train=train[,-1], test=test[,-1], cl=train$y, k=5)
knn.pred<- knn(train=train[,-1], test=test[,-1], cl=train$y, k=5)
sum(myknn.pred!=knn.pred)
myknn<- function(train, test, cl, k){
# define a 0 vector to save your predictions for testing sample
pred<- rep(0, nrow(test))
# obtain the full distance matrix (excluding the column y)
dist.mat<- as.matrix(dist(rbind(train, test)))
# figure out the block you need
row.index<- nrow(train)+1:nrow(test)
col.index<- 1:nrow(train)
submat<- dist.mat[row.index, col.index]
# for loop to find prediction for each testing point
for(i in 1:nrow(test)){
# find the index of k nearest points in training sample
# you may use function `order()` to find the index of nearest point
neighbor.index<- order(submat[i,])
# find y's of those k nearest points
neighbor.y<- neighbor.index[1:k]
# take majority vote as the prediction
pred[i]<- names(which.max(table(cl[neighbor.y])))
}
return(pred)
}
# test your function and compare with knn()
myknn.pred<- myknn(train=train[,-1], test=test[,-1], cl=train$y, k=5)
knn.pred<- knn(train=train[,-1], test=test[,-1], cl=train$y, k=5)
sum(myknn.pred!=knn.pred)
setwd("J:/Github/Karthik/CSRtm")
##################### Redundancy
####### % of 10-grams that occur more than once in each document
load("workspace\CSR_documents_30samples.RData")
##################### Redundancy
####### % of 10-grams that occur more than once in each document
load("workspace/CSR_documents_30samples.RData")
setwd("J:/Github/Karthik/CSRtm")
##################### Redundancy
####### % of 10-grams that occur more than once in each document
load("workspaces/CSR_documents_30samples.RData")
load("J:/Github/Karthik/CSRtm/workspaces/Boilerplate.RData")
load("J:/Github/Karthik/CSRtm/workspaces/CSR_documents_30samples.RData")
library(koRpus.lang.en)
library(stringr)
library(tokenizers)
library(tidyverse)
library(tm)
library(rlist)
t<-list(length=nrow(text_stack_sample))
for(row in 1:nrow(text_stack_sample))
{
print(row)
if (text_stack_sample[row,1] != "")
{
t[[row]] =unlist(tokenize_sentences(removeNumbers(text_stack_sample[row,1])))
}
}
??list.filter
length(t[[1]])
length(t[[1]][1])
str_count(t[[1]][1],'\\w+')
str_count(t[[1]],'\\w+')
t<-list(length=nrow(text_stack_sample))
for(row in 1:nrow(text_stack_sample))
{
print(row)
temp = NULL
if (text_stack_sample[row,1] != "")
{
temp =tokenize_sentences(removeNumbers(text_stack_sample[row,1]))
t[[row]] <- unlist(list.filter(temp,str_count(temp, '\\w+')>9))
}
}
warnings()
t[[1]]
t<-list(length=nrow(text_stack_sample))
for(row in 1:nrow(text_stack_sample))
{
print(row)
if (text_stack_sample[row,1] != "")
{
t[[row]] =unlist(tokenize_sentences(removeNumbers(text_stack_sample[row,1])))
}
}
ngram <- list(length=length(t))
for(i in 1:length(t))
{
print(i)
ngram[[i]] = list(length = length(t[[i]]))
for(j in 1:length(t[[i]]))
{
if(t[[i]][[j]] != "")
{
ngram[[i]][[j]] = tokenize_ngrams(t[[i]][[j]],n=10)
}
}
}
ngram[[1]]
list_tetragrams = list(length(nrow(text_stack_sample)))
for(row in 1:nrow(text_stack_sample))
{
temp  = unlist(ngram[row])
temp = as.data.frame(table(temp))
list_tetragrams[[row]] = temp$temp
}
list_tetragrams[[1]]
Fngram<- unlist(unlist(list_tetragrams))
Fngram<- list(Fngram)
N_table<-as.data.frame(table(Fngram))
names(N_table)
N_table
N_table%>%
arrange(desc(Freq))%>%
##### For document level:
###############
for (i in 1:length(t))
N_table%>%
arrange(desc(Freq))%>%
##### For document level:
###############
for (i in 1:length(t))
N_table%>%
arrange(desc(Freq))
1+1
N_table%>%
arrange(desc(Freq))
N_table%>%
arrange(desc(Freq))
N_table<- N_table%>%
arrange(desc(Freq))
N_table
for (i in 1:length(t))
{
print(i)
temp = 0
for (j in 1:nrow(N_table))
{
ngrams = na.omit(unlist(ngram[[i]]))
if(any(str_detect(ngrams,as.character(N_table[j,"Fngram"]))))
{
temp = temp + 1
}
}
text_stack_sample$DocFlag[i] = temp
}
for (i in 1:length(t))
{
print(i)
temp = 0
for (j in 1:nrow(N_table))
{
ngrams = na.omit(unlist(ngram[[i]]))
if(any(str_detect(ngrams,as.character(N_table[j,"Fngram"]))))
{
temp = temp + 1
}
}
text_stack_sample$DocFlag[i] = temp
}
text_stack_sample$DocFlag
N_table<- N_table%>%
arrange(desc(Freq))%>%
mutate(prop=Freq/30)
N_table
N_table<- N_table%>%
arrange(desc(Freq))%>%
mutate(prop=Freq/30)%>%filter(prop>0.1 & prop<=0.75)
N_table<- N_table%>%
arrange(desc(Freq))%>%
mutate(prop=Freq/30)%>%filter(prop>=0.1 & prop<=0.75)
N_table<- N_table%>%
arrange(desc(Freq))%>%
mutate(prop=Freq/30)%>%filter(prop>=0.09 & prop<=0.75)
N_table<- N_table%>%
arrange(desc(Freq))%>%
mutate(prop=Freq/30)%>%filter(prop<=0.75)
N_table<- N_table%>%
arrange(desc(Freq))%>%
mutate(prop=Freq/30)%>%filter(prop<=0.99)
N_table<- N_table%>%
arrange(desc(Freq))%>%
mutate(prop=Freq/30)%>%filter(prop<=0.99)
N_table<- N_table%>%
arrange(desc(Freq))%>%
mutate(prop=Freq/30)%>%filter(prop<1)
N_table<- N_table%>%
arrange(desc(Freq))%>%
mutate(prop=Freq/30)%>%filter(prop >0.5 & prop<1)
N_table<- N_table%>%
arrange(desc(Freq))%>%
mutate(prop=Freq/30)%>%filter(prop<1)
N_table<- N_table%>%
arrange(desc(Freq))%>%
mutate(prop=Freq/30)%>%filter(prop<1)
N_table<- N_table%>%
arrange(desc(Freq))%>%
mutate(prop=Freq/30)%>%filter(prop>0.01)
N_table<- N_table%>%
arrange(desc(Freq))%>%
mutate(prop=Freq/30)%>%filter(prop>0.01 & prop < 1)
N_table<-as.data.frame(table(Fngram))
N_table<- N_table%>%
arrange(desc(Freq))%>%
mutate(prop=Freq/30)%>%filter(prop>0.01 & prop < 1)
N_table<-as.data.frame(table(Fngram))
N_table2<- N_table%>%
arrange(desc(Freq))%>%
mutate(prop=Freq/30)%>%filter(prop>0.1 & prop < 1)
N_table2<- N_table%>%
arrange(desc(Freq))%>%
mutate(prop=Freq/30)%>%filter(prop>0.01 & prop < 1)
N_table2<- N_table%>%
arrange(desc(Freq))%>%
mutate(prop=Freq/30)%>%filter(prop>0.05 & prop < 1)
N_table2<- N_table%>%
arrange(desc(Freq))%>%
mutate(prop=Freq/30)%>%filter(prop>0.3 & prop < 0.75)
N_table
N_table2<- N_table%>%
arrange(desc(Freq))%>%
mutate(prop=Freq/30)
N_table2
t<-list(length=nrow(text_stack_sample))
for(row in 1:nrow(text_stack_sample))
{
print(row)
if (text_stack_sample[row,1] != "")
{
t[[row]] =unlist(tokenize_sentences(removeNumbers(text_stack_sample[row,1])))
}
}
##################### Redundancy
####### % of 10-grams that occur more than once in each document
load("workspaces/CSR_documents_30samples.RData")
t<-list(length=nrow(text_stack_sample))
for(row in 1:nrow(text_stack_sample))
{
print(row)
if (text_stack_sample[row,1] != "")
{
t[[row]] =unlist(tokenize_sentences(removeNumbers(text_stack_sample[row,1])))
}
}
length(t[[1]])
ngram <- list(length=length(t))
for(i in 1:length(t))
{
print(i)
ngram[[i]] = list(length = length(t[[i]]))
for(j in 1:length(t[[i]]))
{
if(t[[i]][[j]] != "")
{
ngram[[i]][[j]] = tokenize_ngrams(t[[i]][[j]],n=10)
}
}
}
list_tetragrams = list(length(nrow(text_stack_sample)))
for(row in 1:nrow(text_stack_sample))
{
temp  = unlist(ngram[row])
temp = as.data.frame(table(temp))
list_tetragrams[[row]] = temp$temp
}
list_tetragrams[[1]]
Fngram<- unlist(unlist(list_tetragrams))
Fngram<- list(Fngram)
N_table<-as.data.frame(table(Fngram))
N_table2<- N_table%>%
arrange(desc(Freq))%>%
mutate(prop=Freq/30)
for (i in 1:length(t))
{
print(i)
temp = 0
for (j in 1:nrow(N_table2))
{
ngrams = na.omit(unlist(ngram[[i]]))
print(j)
if(any(str_detect(ngrams,as.character(N_table2[j,"Fngram"]))))
{
temp = temp + 1
}
}
text_stack_sample$DocFlag[i] = temp
}
