install.packages("MASS")
### R file test
Sys.Date()
### R file test
Sys.Date()
qt(0.9,15)
####if the population sd is known as 2
k_lb <- 1002*3/sqrt(16)
####if the population sd is known as 2
k_lb <- 10-2*3/sqrt(16)
k_ub <- 10+2*3/sqrt(16)
a_k <- c(k_lb, k_ub)
a_k
####if we do not know population sd, and test at 95% confidence
tstar<- qt(0.975,15)
uk_lb <- 10-tstar*3/sqrt(16)
uk_up <- 10+tstar*3/sqrt(16)
uk_ub <- 10+tstar*3/sqrt(16)
ak <- c(uk_lb, uk_ub)
a_uk <- c(uk_lb, uk_ub)
a_uk
rm(ak)
rm(uk_up)
tstar <- qt(.975,15)
p_lb <- 10 - tstar*3*(1+1/sqrt(16))
p_ub <- 10 + tstar*3*(1+1/sqrt(16))
pred<-c(p_lb,p_ub)
pred
a_uk
pred<-c(p_lb,p_ub)
pred
pred<-c(p_lb, p_ub)
pred
pred<-c(p_lb, p_ub)
pred
rm(p_lb)
rm(p_ub)
p_lb <- 10 - tstar*3*(1+1/sqrt(16))
p_ub <- 10 + tstar*3*(1+1/sqrt(16))
pred <- c(p_lb, p_ub)
pred
setwd("J:/Github/Karthik/CSRtm")
##################### Redundancy
####### % of 10-grams that occur more than once in each document
load("workspaces/CSR_documents_30samples.RData")
library(koRpus.lang.en)
library(stringr)
library(tokenizers)
library(tidyverse)
library(tm)
library(rlist)
################## load all the packages
library(koRpus.lang.en)
library(stringr)
library(tokenizers)
library(tidyverse)
library(tm)
library(rlist)
t<-list(length=nrow(text_stack_sample))
for(row in 1:nrow(text_stack_sample))
{
print(row)
if (text_stack_sample[row,1] != "")
{
t[[row]] =unlist(tokenize_sentences(removeNumbers(text_stack_sample[row,1])))
}
}
for(i in 1:length(t))
{
print(i)
ngram = NULL
for(j in 1:length(t[[i]]))
{
if(t[[i]][[j]] != "")
{
ngram[[i]][[j]] = tokenize_ngrams(t[[i]][[j]],n=10)
}
}
}
ngram[[1]][1]
ngram[[1]][[1]]
################  10-ngrams for all documents
ngram <- list(length=length(t))
ngram
rm(ngram)
for(i in 1:length(t))
{
print(i)
ngram[[i]] = list(length = length(t[[i]]))
for(j in 1:length(t[[i]]))
{
if(t[[i]][[j]] != "")
{
ngram[[i]][[j]] = tokenize_ngrams(t[[i]][[j]],n=10)
}
}
}
################  10-ngrams for all documents
ngram<- NULL
for(i in 1:length(t))
{
print(i)
ngram[[i]] = list(length = length(t[[i]]))
for(j in 1:length(t[[i]]))
{
if(t[[i]][[j]] != "")
{
ngram[[i]][[j]] = tokenize_ngrams(t[[i]][[j]],n=10)
}
}
}
ngram[[1]][1]
################ try to find number of 10grams in each document
list_tetragrams = NULL
for(row in 1:nrow(text_stack_sample))
{
temp  = unlist(ngram[row])
temp = as.data.frame(table(temp))
list_tetragrams[[row]] = temp$temp
}
Fngram<- list(unlist(unlist(list_tetragrams)))
N_table<-as.data.frame(table(Fngram))
names(N_table)
N_table2<- N_table%>%
arrange(desc(Freq))%>%
mutate(prop=Freq/30)#%>%filter(prop>0.3 & prop < 0.75)
N_table2
N_table2<- N_table%>%
arrange(desc(Freq))%>%
mutate(prop=Freq/nrow(text_stack_sample))#%>%filter(prop>0.3 & prop < 0.75)
N_table2
################ find the repetition
as.data.frame(table(unlist(ngram[1]))
################ find the repetition
as.data.frame(table(unlist(ngram[1])))
################ find the repetition
as.data.frame(table(unlist(ngram[1])))
################ find the repetition
as.data.frame(table(unlist(ngram[1])))%>%arrange(desc())
################ find the repetition
as.data.frame(table(unlist(ngram[1])))%>%arrange(desc(Freq))
################ find the repetition
as.data.frame(table(unlist(unlist(ngram))))%>%arrange(desc(Freq))
################ find the repetition
Fngram<- as.data.frame(table(unlist(unlist(ngram))))%>%arrange(desc(Freq))
Fngram
head(Fngram)
list_tetragrams = NULL
for(row in 1:nrow(text_stack_sample))
{
print(row)
temp  = unlist(ngram[row])
temp = as.data.frame(table(temp))
list_tetragrams[[row]] = temp$temp
}
Fngram<- list(unlist(unlist(list_tetragrams)))
N_table<-as.data.frame(table(Fngram))
N_table2<- N_table%>%
arrange(desc(Freq))%>%
mutate(prop=Freq/nrow(text_stack_sample))
N_table2
TenGram <- lapply(ngram, as.data.frame(table(unlist())))
TenGram <- lapply(unlist(ngram), as.data.frame(table()))
TenGram <- lapply(ngram,unlist)
TenGram <- lapply(TenGram, table)
TenGram <- lapply(TenGram, as.data.frame)
TenGram[1]
head(TenGram[2])
head(TenGram[2])
head(TenGram[2],10)
TenGram[1]
TenGram[2]
TenGram[3]
TenGram <- lapply(ngram,unlist)
TenGram <- lapply(TenGram, table)
TenGram[3]
TenGram <- lapply(TenGram, as.data.frame)
TenGram[3]
TenGram <- lapply(ngram,unlist)
TenGram <- lapply(TenGram, table)
TenGram <- lapply(TenGram, as.data.frame)
TenGram[3]
TenGram[30]
TenGram[25]
TenGram[25]%>%
sum(Freq>=2)/sum(Freq)
sum(TenGram[25]$Freq>=2)/sum(TenGram[25]$Freq)
sum(TenGram[25]$Freq>=2)
sum(TenGram[25]$Freq)
sum(TenGram[25][[1]]$Freq>=2)/sum(TenGram[25][[1]]$Freq)
sum(TenGram[25][[1]]$Freq>=2)
sum(TenGram[1][[1]]$Freq>=2)/sum(TenGram[1][[1]]$Freq)
length(TenGram)
for (i in 1:length(TenGram)){
text_stack_sample$Redundancy[i]<-sum(TenGram[i][[1]]$Freq>=2)/sum(TenGram[i][[1]]$Freq)
}
text_stack_sample$Redundancy
save(text_stack_sample,"worksapces/Redundancy.RData")
save(text_stack_sample, file = "worksapces/Redundancy.RData")
save(text_stack_sample, file = "worksapces/Redundancy.RData")
save(text_stack_sample, file = "worksapces/Redundancy.RData")
setwd("J:/Github/Karthik/CSRtm")
save(text_stack_sample, file = "worksapces/Redundancy.RData")
save(text_stack_sample, file = "workspaces/Redundancy.RData")
text_stack_sample$Redundancy
mean(text_stack_sample$Redundancy)
